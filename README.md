 მოცემულ პროექტში ჩვენი მიზანია, ვიწინასწარმეტყველოთ Walmart-ის სხვადასხვა ფილიალის კვირეული გაყიდვები დეპარტამენტების მიხედვით. მოცემული მონაცემები წარმოადგენს დროის მწკრივებს და ისტორიული ინფორმაცია გვაქვს წარსულში განსხვავებული ფილიალის დეპარტამენტებში გაყიდვებთან დაკავშირებით. ჩვენ ვცადეთ ტრადიციული ARIMA-ს გამოყენება მოცემული ამოცანის გადასაჭრელად.


მონაცემების მომზადების ნაწილში გამოვიყვანეთ 4 სხვადასხვა დღესასწაულის ინდიკატორული ცვლადი, რადგან აღნიშნულ დღესასწაულების დღეებში გაყიდვების პროგნოზირება მნიშვნელოვანია. ასევე მონაცემებში აღმოჩენილი იყო სამიზნე ცვლადის უარყოფითი მნიშვნელობები, რომლებიც გადავყარეთ. რაც შეეხება გამოტოვებულ მნიშვნელობებს, მოდელირებისთვის საჭირო ცვლადებში ის არ შეგხვდა(ის მხოლოდ Markdown ტიპის ცვლადებშია, რომლებიც inference-ის დროს არ გვაქვს. ტრადიციული ARIMA-ს შემთხვევაში, განსხვავებით tft-სგან, ამის გამოყენება არ შეგვიძლია).

სულ თავიდან მოდელების რაოდენობის სიმცირის თვალსაზრისით გამოვიყვანეთ თითოეულ ფილიალში ჯამური გაყიდვები(დეპარტამენტებს არ ვითვალისწინებთ) და ისე ავაგეთ ARIMA მოდელი. შემდგომ მიდგომა გავხადეთ უფრო გრანულარული და თითოეული ფილიალისა და დეპარტამენტის ჭრილში ავაგეთ ARIMA მოდელი (1, 1, 1) პარამეტრებით. საბოლოო მიდგომაში დავლოგეთ თითოეული კომბინაციის მიხედვით აგრეგირებული მეტრიკები, როგორიცაა MAE, MAPE, RMSE. თითოეული ექსპერიმენტის შედეგები დალოგილია mlflow-ზე. 







მონაცემების მოკვლევის ეტაპზე გაკეთდა:
1. სეზონური დეკომპოზიცია(seasonal decomposition), რათა ვიზუალურად წარმოგვედგინა მთელი სამიზნე ცვლადის განაწილება, ტრენდის ნაწილი, სეზონურობის ნაწილი და ხმაური

   <img width="655" height="500" alt="image" src="https://github.com/user-attachments/assets/f686f18a-f5ef-46e8-9ea0-1acf35236242" />

მოცემულ გრაფიკზე ჩვენ ვხედავთ პიკებს, რომლებიც სეზონური შოპინგის პერიოდებითაა გამოწვეული. ტრენდი თავიდან მეტნაკლებად სტაბილურია, შემდგომ მცირდება და ბოლოს იზრდება. შესაძლოა აქ გაყიდვების ქცევა შეიცვალა, რაც ეკონომიკურ ფაქტორებთანაც იყოს კავშირში.
ჩვენ ასევე ვხედავთ ყოველკვირეულ/ყოველწლიურ სეზონურობასაც. ხმაურის ნაწილში კი არაა მკვეთრად გამოკვეთილი კანონზომიერება, თუმცა ვხედავთ რამდენიმე ანომალურ მნიშვნელობასაც. 

მოცემული დროითი მწკრივის მონაცემები აშკარად არაა სტაციონარული.

2. ჩვენ სამიზნე ცვლადის lag-ის ცვლადებს გამოვიყვანეთ.
3. ვცადეთ გადიფერენცირება, რათა შეგვემოწმებინა დროის მწკრივის სტაციონარულობა.  ამისთვის ავიღეთ შემთხვევითი შერჩევა და 1-ელ გავადიფერენცირეთ მონაცემები, რის შემდეგაც დიკი ფულერის კრიტერიუმით დროის მწკრივი გახდა სტაციონარული(თავიდან არ იყო).

4. ავაგეთ ავტოკორელაციის და ნაწილობრივი ავტოკორელაციის გრაფიკები
   <img width="582" height="808" alt="image" src="https://github.com/user-attachments/assets/c3758e11-9058-4dcc-aef8-3024b30d28a9" />
გრაფიკიდან გამომდინარე, თითქმის ყველა ლაგი(გარდა მე-7სა ხვდება ნდობის არეში, ხოლო მე-7 ლაგში არსებული ამოვარდნა სუსტ სეზონურ დამოკიდებულებაზე შეიძლება მიუთითებდეს, რომელსაც შემდგომ SARIMA მოდელში გამოვიყენებთ).

5. გამოვიყვანეთ წლის, თვის, კვირისა და კვარტლის ცვლადები, ასევე დღესასწაულის ინდიკატორის ცვლადები

6.შევამოწმეთ გარე ფაქტორების კორელაცია გაყიდვებთან
<img width="927" height="698" alt="image" src="https://github.com/user-attachments/assets/3dae7f73-f114-4298-94c3-5527761b29e0" />
მოცემული გრაფიკი არ მიუთითებს ძლიერ კორელაციაზე გარეგან ფაქტორებსა და გაყიდვებს შორის(პირდაპირი კორელაცია ორ სიდიდეს შორის)

7. ავაგეთ განაწილების გრაფიკები, რომლის შემდგომაც გავუმკლავდით ანომალურ მნიშვნელობებს
   <img width="1365" height="564" alt="image" src="https://github.com/user-attachments/assets/f5b6868d-ecd8-4dd1-bdc0-e7961c2ce0cf" />

თითოეული მაღაზიისა და დეპარტამენტისთვის განისაზღვრა წილი ასეთი ანომალური მნიშვნელობებისა(რომლებიც სცდება აღნიშნულ საზღვრებს) და ეს propensity პარამეტრები გამოვიყენეთ დამატებით ცვლადად.
8. გადავყარეთ MarkDown ტიპის ცვლადები მათი დიდი რაოდენობის უცნობი მნიშვნელობების გამო
9. გადავყარეთ უარყოფითი გაყიდვების მქონე ჩანაწერები
